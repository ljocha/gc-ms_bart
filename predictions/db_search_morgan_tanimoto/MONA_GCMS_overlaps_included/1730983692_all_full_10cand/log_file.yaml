command: ../predict_db_search.py --output-folder predictions --config-file configs/predict_db_search_mt_extra_libs.yaml
  --num-workers 25
dataset:
  data_split: all
  dataset_name: MONA_GCMS_overlaps_included
  query_data: data/extra_libraries/MONA_GCMS/MONA_GCMS_overlaps_included.jsonl
  reference_data: data/nist/train.jsonl
filtering_args:
  max_mol_repr_len: 100
  max_mz: 500
  max_num_peaks: 300
  mol_repr: smiles
general:
  additional_naming_info: ''
  num_candidates: 10
  ranking_function: morgan_tanimoto
start_loading_time: 07/11/2024 13:48:11
tokenizer_path: tokenizer/tokenizer_mf10M.model
finished_time_utc: 07/11/2024 13:48:12
generation_time: 00:00:00
wall_time_utc: 00:00:00
evaluation_0:
    average_num_of_predictions: '9.999438580732091'
    eval_config:
        do_db_search: false
        filtering_args:
            max_mol_repr_len: 100
            max_mz: 500
            max_num_peaks: 300
            mol_repr: smiles
        fingerprint_type: morgan
        fp_simil_function: tanimoto
        on_the_fly: true
        save_best_predictions: true
        threshold: 0.85
    eval_time: 00:00:35
    formula_stats:
        num_all_correct_formulas: 15670 / 178110
        num_at_least_one_correct_formula: '13282'
        num_correct_formulas_at_best_prob: '11834'
        num_correct_formulas_at_best_simil: '12703'
        rate_of_all_correct_formulas: '0.08797933861097075'
        rate_of_at_least_one_correct_formula: '0.7456770716370986'
        rate_of_correct_formulas_at_best_prob: '0.6643835616438356'
        rate_of_correct_formulas_at_best_simil: '0.7131708960251516'
    hit_at_k_prob: '[(1, 0.7433752526386705)]'
    labels_path: data/extra_libraries/MONA_GCMS/MONA_GCMS_overlaps_included.jsonl
    molecular_weight_stats:
        mean_absolute_mw_difference_best_prob: '21.461785753012943'
        mean_absolute_mw_difference_best_simil: '21.461785753012943'
        mean_relative_mw_difference_best_prob: 11.62%
        mean_relative_mw_difference_best_simil: 11.62%
        rate_of_exact_mw_prob: '0.66404671008309'
        rate_of_exact_mw_simil: '0.66404671008309'
        rate_of_exact_nominal_mw_prob: '0.6645519874242084'
        rate_of_exact_nominal_mw_simil: '0.6645519874242084'
        rate_of_mw_difference_less_than_1_best_prob: '0.6740961149786661'
        rate_of_mw_difference_less_than_1_best_simil: '0.6740961149786661'
    num_datapoints_tested: '17812'
    num_empty_preds: '0'
    num_predictions_at_k_counter: '[17812, 17812, 17812, 17812, 17812, 17812, 17812,
        17812, 17811, 17803]'
    precise_preds_stats:
        num_precise_preds_probsort: '11661'
        num_precise_preds_similsort: '12507'
        rate_of_precise_preds_probsort: '0.6546710083090052'
        rate_of_precise_preds_similsort: '0.7021670783741298'
    simil_1_hits:
        counter_multiple_hits: dict_items([(1, 11373), (2, 203), (10, 1004), (8, 78),
            (3, 138), (4, 133), (6, 83), (7, 91), (9, 84), (5, 54)])
        num_1_hits_as_first_probsort: '13241'
        num_1_hits_as_first_similsort: '13241'
        num_fp_simil_fail_prob: '1580'
        num_fp_simil_fail_simil: '734'
        rate_of_1_hits_as_first_probsort: '0.7433752526386705'
        rate_of_1_hits_as_first_similsort: '0.7433752526386705'
    start_time_utc: 07/11/2024 18:56:47
    threshold_stats:
        num_better_than_threshold_probsort: '13763'
        num_better_than_threshold_similsort: '13763'
        rate_of_better_than_threshold_probsort: '0.7726813384235347'
        rate_of_better_than_threshold_similsort: '0.7726813384235347'
        threshold: '0.85'
    topk_probsort: '[0.9155178614835296, 0.707429406917876, 0.6621192846986763, 0.6357569346724072,
        0.616212906163409, 0.6017199217110262, 0.5891750875034482, 0.5784032621294241,
        0.5686645033110761, 0.56049110795259]'
    topk_similsort: '[0.9155178614835296, 0.707429406917876, 0.6621192846986763, 0.6357569346724072,
        0.616212906163409, 0.6017199217110262, 0.5891750875034482, 0.5784032621294241,
        0.5686645033110761, 0.56049110795259]'
