command: predict.py --checkpoint checkpoints/finetune_clean/apricot-frost-534_exp1_log_39_1.2/checkpoint-73738
  --output-folder predictions --config-file configs/predict_nist_valid_beam10_exp1_log_39_1.2.yaml
cuda_visible_devices: '0'
dataloader:
  batch_size: 1
  num_workers: 1
dataset:
  data_path: data/nist/valid.jsonl
  data_split: valid
  dataset_name: NIST
general:
  additional_naming_info: beam10
  device: cuda
generation_args:
  do_sample: false
  length_penalty: 1.0
  max_length: 200
  num_beams: 10
  num_return_sequences: 10
  penalty_alpha: null
  temperature: null
  top_k: null
  top_p: null
preprocess_args:
  inference_mode: true
  log_base: 1.2
  log_shift: 39
  max_cumsum: null
  max_mol_repr_len: 100
  max_mz: 500
  max_num_peaks: 300
  mol_repr: smiles
  restrict_intensities: false
  source_token: <nist>
start_loading_time: 07/10/2024 00:15:13
tokenizer_path: tokenizer/tokenizer_mf10M.model
finished_time_utc: 09/10/2024 04:03:06
generation_time: 03:47:50
wall_time_utc: 03:47:53
evaluation_0:
    average_num_of_predictions: '8.712708947013521'
    db_search:
        mean_db_score: '0.3873157933415626'
        mean_fpsd_score_probsort: '0.18074991471521515'
        mean_fpsd_score_similsort: '0.32820105384523385'
        rate_of_spectus_wins_probsort: '0.6655073286723214'
        rate_of_spectus_wins_similsort: '0.840472725982184'
        rate_of_ties_probsort: '0.09152855165560564'
        rate_of_ties_similsort: '0.09152855165560564'
        ties:
            mean_tie_simils_probsort: '0.8210662200761358'
            mean_tie_simils_similsort: '0.8636575876682976'
            num_of_ties_probsort: '2579'
            num_of_ties_simils_equal_to_1_probsort: '1666'
            num_of_ties_simils_equal_to_1_similsort: '1777'
            num_of_ties_similsort: '2579'
            rate_of_ties_simils_equal_to_1_probsort: '0.6459868165955797'
            rate_of_ties_simils_equal_to_1_similsort: '0.6890267545560295'
    eval_config:
        do_db_search: true
        filtering_args:
            max_mol_repr_len: 100
            max_mz: 500
            max_num_peaks: 300
            mol_repr: smiles
        fingerprint_type: morgan
        fp_simil_function: tanimoto
        on_the_fly: true
        save_best_predictions: true
        threshold: 0.85
    eval_time: 00:01:14
    formula_stats:
        num_all_correct_formulas: 52476 / 245498
        num_at_least_one_correct_formula: '19895'
        num_correct_formulas_at_best_prob: '13833'
        num_correct_formulas_at_best_simil: '16843'
        rate_of_all_correct_formulas: '0.21375326886573415'
        rate_of_at_least_one_correct_formula: '0.7060723284948717'
        rate_of_correct_formulas_at_best_prob: '0.4909323206870852'
        rate_of_correct_formulas_at_best_simil: '0.5977570358803279'
    hit_at_k_prob: '[(1, 0.30056429002377827), (2, 0.3811974305284452), (3, 0.4242112361145615),
        (4, 0.45065124037335413), (5, 0.4687156191219789), (6, 0.48198885615927883),
        (7, 0.49164211945913333), (8, 0.49760442914433756), (9, 0.5015438123292046),
        (10, 0.5031408595663129)]'
    labels_path: data/nist/valid_with_db_index.jsonl
    molecular_weight_stats:
        mean_absolute_mw_difference_best_prob: '9.87818323020368'
        mean_absolute_mw_difference_best_simil: '10.342605476707252'
        mean_relative_mw_difference_best_prob: 3.72%
        mean_relative_mw_difference_best_simil: 3.85%
        rate_of_exact_mw_prob: '0.4844376619228449'
        rate_of_exact_mw_simil: '0.5241509032189374'
        rate_of_exact_nominal_mw_simil: '0.5402278454058275'
        rate_of_mw_difference_less_than_1_best_prob: '0.5369982609930085'
        rate_of_mw_difference_less_than_1_best_simil: '0.5598182915143557'
    num_datapoints_tested: '28177'
    num_empty_preds: '6'
    num_predictions_at_k_counter: '[28177, 28142, 28031, 27771, 27271, 26389, 24948,
        22663, 19072, 13040]'
    precise_preds_stats:
        num_precise_preds_probsort: '7765'
        num_precise_preds_similsort: '14015'
        rate_of_precise_preds_probsort: '0.2755793732476843'
        rate_of_precise_preds_similsort: '0.49739148951272316'
    simil_1_hits:
        counter_multiple_hits: dict_items([(1, 11237), (2, 1093), (9, 19), (5, 213),
            (3, 941), (6, 95), (7, 69), (4, 461), (8, 38), (10, 11)])
        num_1_hits_as_first_probsort: '8469'
        num_1_hits_as_first_similsort: '14177'
        num_fp_simil_fail_prob: '704'
        num_fp_simil_fail_simil: '162'
        rate_of_1_hits_as_first_probsort: '0.30056429002377827'
        rate_of_1_hits_as_first_similsort: '0.5031408595663129'
    start_time_utc: 05/11/2024 10:26:28
    threshold_stats:
        num_better_than_threshold_probsort: '8867'
        num_better_than_threshold_similsort: '14439'
        rate_of_better_than_threshold_probsort: '0.31468928558753595'
        rate_of_better_than_threshold_similsort: '0.5124392234801434'
        threshold: '0.85'
    topk_probsort: '[0.5680657080567778, 0.4936523908892494, 0.45891353463533013,
        0.43711296739024375, 0.4226689082634564, 0.4088390430523267, 0.3957013313701228,
        0.3777098039170313, 0.36149564856320554, 0.3384825807883475]'
    topk_similsort: '[0.7155168471867964, 0.5614466207330299, 0.4958848834845134,
        0.4471935921524548, 0.4077661541073651, 0.37236762528756506, 0.3393552707284333,
        0.30592589952318266, 0.27273091263857413, 0.23997411210071443]'
