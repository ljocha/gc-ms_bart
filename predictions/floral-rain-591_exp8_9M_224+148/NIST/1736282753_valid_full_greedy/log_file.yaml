command: predict.py --checkpoint ../checkpoints/finetune_clean/floral-rain-591_exp8_9M_224+148/checkpoint-147476
  --output-folder predictions --config-file configs/predict_nist_valid_greedy.yaml
cuda_visible_devices: GPU-9c7e3cb8-d7e4-720e-d6c3-bd8b1d5256d9
dataloader:
  batch_size: 1
  num_workers: 1
dataset:
  data_path: data/nist/valid.jsonl
  data_split: valid
  dataset_name: NIST
general:
  additional_naming_info: greedy
  device: cuda
generation_args:
  do_sample: false
  length_penalty: 1.0
  max_length: 200
  num_beams: 1
  num_return_sequences: 1
  penalty_alpha: null
  temperature: null
  top_k: null
  top_p: null
preprocess_args:
  inference_mode: true
  log_base: 1.28
  log_shift: 29
  max_cumsum: null
  max_mol_repr_len: 100
  max_mz: 500
  max_num_peaks: 300
  mol_repr: smiles
  restrict_intensities: false
  source_token: <nist>
start_loading_time: 07/01/2025 21:45:52
tokenizer_path: tokenizer/tokenizer_mf10M.model
finished_time_utc: 08/01/2025 01:02:25
generation_time: 03:16:30
wall_time_utc: 03:16:33
evaluation_0:
    average_num_of_predictions: '0.9883238101998083'
    eval_config:
        do_db_search: false
        filtering_args:
            max_mol_repr_len: 100
            max_mz: 500
            max_num_peaks: 300
            mol_repr: smiles
        fingerprint_type: morgan
        fp_simil_function: tanimoto
        on_the_fly: true
        save_best_predictions: true
        threshold: 0.85
    eval_time: 00:00:24
    formula_stats:
        num_all_correct_formulas: 18590 / 27848
        num_at_least_one_correct_formula: '18590'
        num_correct_formulas_at_best_prob: '18590'
        num_correct_formulas_at_best_simil: '18590'
        rate_of_all_correct_formulas: '0.6675524274633726'
        rate_of_at_least_one_correct_formula: '0.6597579586187315'
        rate_of_correct_formulas_at_best_prob: '0.6597579586187315'
        rate_of_correct_formulas_at_best_simil: '0.6597579586187315'
    hit_at_k_prob: '[(1, 0.4195975440962487)]'
    labels_path: data/nist/valid.jsonl
    molecular_weight_stats:
        mean_absolute_mw_difference_best_prob: '5.979120383397716'
        mean_absolute_mw_difference_best_simil: '5.979120383397716'
        mean_relative_mw_difference_best_prob: 2.14%
        mean_relative_mw_difference_best_simil: 2.14%
        rate_of_exact_mw_prob: '0.6502821450118891'
        rate_of_exact_mw_simil: '0.6502821450118891'
        rate_of_exact_nominal_mw_prob: '0.6931539908435959'
        rate_of_exact_nominal_mw_simil: '0.6931539908435959'
        rate_of_mw_difference_less_than_1_best_prob: '0.7156901018561238'
        rate_of_mw_difference_less_than_1_best_simil: '0.7156901018561238'
    num_datapoints_tested: '28177'
    num_empty_preds: '329'
    num_predictions_at_k_counter: '[28177]'
    precise_preds_stats:
        num_precise_preds_probsort: '11462'
        num_precise_preds_similsort: '11462'
        rate_of_precise_preds_probsort: '0.40678567626078005'
        rate_of_precise_preds_similsort: '0.40678567626078005'
    simil_1_hits:
        counter_multiple_hits: dict_items([(1, 11823)])
        num_1_hits_as_first_probsort: '11823'
        num_1_hits_as_first_similsort: '11823'
        num_fp_simil_fail_prob: '361'
        num_fp_simil_fail_simil: '361'
        rate_of_1_hits_as_first_probsort: '0.4195975440962487'
        rate_of_1_hits_as_first_similsort: '0.4195975440962487'
    start_time_utc: 08/01/2025 09:39:32
    threshold_stats:
        num_better_than_threshold_probsort: '12098'
        num_better_than_threshold_similsort: '12098'
        rate_of_better_than_threshold_probsort: '0.4293572772119104'
        rate_of_better_than_threshold_similsort: '0.4293572772119104'
        threshold: '0.85'
    topk_probsort: '[0.6491252251460597]'
    topk_similsort: '[0.6491252251460597]'
